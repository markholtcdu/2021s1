<!DOCTYPE html>
<html lang="en">
<head>
    <META charset="UTF-8">
    <META NAME="AUTHOR" content="Inchu">
    <link rel="stylesheet" href="2.css">
    <title>Artificial Inteligence--AI</title>
</head>
<body>
<header>
<div class="head"><h1 align="center"><br>Inchu's Ideas of Artificial Inteligence</h1></div>
</header>
<article>
<div class="box">
<div class="top">
<h2>AI's Brian-Statistical algorithms</h2>
<br>
<li>FACT 1-Decision Tree A simple method of dividing the decision space into multiple boxes can be expressed as a so-called decision tree </li>
<br>
<li>A Decision Tree is a tree hierarchical structure with two types of nodes. First, internal nodes/decision nodes which splits the data (represented as circles) and second, leaf nodes/prediction nodes which makes a prediction (represented as hexagons). A Decision Tree can be deeper and wider depending upon the characteristics of data and/or amount of data. Decision nodes are used to examine the value of a given attribute.It is often observed that ensemble of trees perform better with respect to stand alone tree. (Ankit & Sanjay 2016)</li>
<br><br>
<li>FACT 2-Support vector machines use arbitrary rows to cut the decision space into blogs</li>
<br>
<li>SVMs have  been  successfully  applied  to  a  number  of  applications ranging  from particle identification,  face identification, and  text categorization  to  engine  knock  detection,  bioinformatics,  and database  marketing. (Bennett & Campbell 2000)</li>
</div>
</div>

<div class="box">
<div class="top">
<h2>AI's neural-Artificial neural Network</h2>
<br>
<li>FACT 1-Artificial neurons accept digital inputs like human neurons, combine them, and then output digital</li>
<br>
<li>Multiplicative neuron model-based artificial neural networks are one of the artificial neural network types which have been proposed recently and have produced successful forecasting results.The superior forecasting performance of the proposed Gaussian activation function-based multiplicative neuron model artificial neural network was proved by applying it to real-life time series.(Gundogdu et al. 2016)</li>
<br><br>
<li>FACT 2-Recently, based on powerful processors and networks, deep neural networks have become practical. Years ago. Google and Lianlu show a deep neural network that can find faces and humans in photos. </li>
<br>
<li>Deep neural network (DNN) models have achieved great success in many applications, including predicting the pharmacological properties of drugs and drug reuse. Hou et al. (2019) proposed a deep neural network to predict drug-drug interaction types, and achieved a good performance with an accuracy and AUC of 93.2% and 0.94 in the test set, respectively.</li>
</div>
</div>

<div class="box">
<div class="top">
<h2>The future-Strong AI </h2>
<br>
<li>FACT 1-The explosive growth of digital knowledge as the perfect kindling for strong AI. In 2011, IBMDE WATSON consulted and integrated information in 200 million pages of content, including all wikipedia, and defeated its human competitor in Jeopardy </li>
<br>
<li>Current machine learning systems operate, almost exclusively, in a statistical, or model-blind mode, which entails severe theoretical limits on their power and performance. Such systems cannot reason about interventions and retrospection and, therefore, cannot serve as the basis for strong AI. To achieve human level intelligence, learning machines need the guidance of a model of reality, similar to the ones used in causal inference.(Pearl 2018)</li>
<br><br>
<li>FACT 2-Reinforcement learning: AI can not only swallow a lot of information, but also learn much faster than humans. AlphaGo launched by Google in 2016 discovered successful strategies by copying millions of times to understand what works. </li>
<br>
<li>Reinforcement learning is the problem faced by an agent that learns behavior through trial-and-error interactions with a dynamic environment. central issues of reinforcement learning, including trading off exploration and exploitation, establishing the foundations of the field via Markov decision theory, learning from delayed reinforcement, constructing empirical models to accelerate learning, making use of generalization and hierarchy, and coping with hidden state.(Kaelbling et al. 1996)</li>
</div>
</div>

</article>
<footer>
<h2>Reference List</h2>
<br>
<a href="https://dl.acm.org/doi/pdf/10.1145/2998476.2998478"><li>Ankit, D & Sanjay, C 2016, 'Distributed Decision Tree', <i>COMPUTE '16: Proceedings of the 9th Annual ACM India Conference, </i> pp. 43–50</li></a>
<a href="https://dl.acm.org/doi/10.1145/380995.380999"><li>Bennett, K & Campbell, C 2000, 'Support vector machines: hype or hallelujah?', <i>ACM SIGKDD Explorations Newsletter, </i>Vol. 2, No.2</a>
<a href="https://dl.acm.org/doi/10.1007/s00521-015-1908-x"><li>Gundogdu, O, Egrioglu, E, Aladag, CH & Yolcu,U 2016, 'Multiplicative neuron model artificial neural network based on Gaussian activation function', <i>Neural Computing and Applications, </i>Vol. 27, No.4</a>
<a href="https://dl.acm.org/doi/10.1145/3318299.3318323"><li>Hou, X, You, J & Hu, P 2019, 'Predicting Drug-Drug Interactions Using Deep Neural Network', <i>ICMLC '19: Proceedings of the 2019 11th International Conference on Machine Learning and Computing, </i> pp. 168–172</li></a>
<a href="https://dl.acm.org/doi/10.5555/1622737.1622748"><li>Kaelbling, LP, Littman,ML. & Moore, AW.  1996, 'Reinforcement learning: a survey', <i>Journal of Artificial Intelligence Research, </i>Vol. 4, No.1</a>
<a href="https://dl.acm.org/doi/10.1145/3159652.3176182"><li>Pearl, J 2018, 'Theoretical Impediments to Machine Learning With Seven Sparks from the Causal Revolution', <i>:WSDM '18: Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining, </i>pp. 3</a>
</footer>
</body>
</html>
